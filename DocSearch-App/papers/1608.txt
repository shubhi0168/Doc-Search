CS 

 Distributed computing  

File is a super abstraction of hypothetically huge volume of information stored in containers (disk blocks) which is persists for very long time (memory abstraction). File is linear Array of bites and blocks of bytes accessed by multiple clients which is controlled by File system. File System function is disk seek, read maximum information from container and maps file names and offsets to disk blocks for better read and write operations. File system is logic to device how Information is stockpiled and how effectively to retrieve it. File system manages references (pointers) to memory block and assist to seek information in feasible manner. Without which data would be placed in large heaps of memory at location unknown to operating system to manage resources effectively. File System is structure and sense rules accustomed in managing clusters of data is termed as file system. Current age is age of High performance information processing and intelligent knowledge generation which urges for better Scalable File System. Current File System come with Numerous limitations as architecture design pattern limitations, I/O Operational, component failure, reliability issue, data decomposition, fault Tolerance etc. This manuscript give a first Survey first step towards synchronized research. This is our First research article on Scalable File System which facilities view map of new Scalable File System. Beta Survey Methodology is been incorporated with pattern of Abstract methodology and scope Writing for every research article related to Scalable file system Survey. The Key point answer of Conclusion is Luster a scalable file system which has been used as core in development of world top 100 supercomputers which fulfills key space to be scalable file System Future research work would be implementation of Luster File System and Evaluation on parameters of global name space IOPS and Luster File Size, No of clients and OST's used with Throughput MBPS and read/write pattern evaluation.